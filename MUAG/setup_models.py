"""
Script de setup et t√©l√©chargement des mod√®les
"""
import os
import sys
from pathlib import Path


def print_header(text):
    print("\n" + "="*60)
    print(f"  {text}")
    print("="*60 + "\n")


def check_python_version():
    """V√©rifie la version de Python"""
    print_header("üêç V√©rification de Python")
    
    version = sys.version_info
    print(f"Version Python: {version.major}.{version.minor}.{version.micro}")
    
    if version.major < 3 or (version.major == 3 and version.minor < 8):
        print("‚ùå Python 3.8+ requis!")
        return False
    
    print("‚úÖ Version Python OK")
    return True


def install_requirements():
    """Installe les d√©pendances"""
    print_header("üì¶ Installation des d√©pendances")
    
    requirements_file = Path(__file__).parent / "requirements.txt"
    
    if not requirements_file.exists():
        print("‚ùå requirements.txt non trouv√©!")
        return False
    
    print("Installation en cours (cela peut prendre plusieurs minutes)...")
    print("Packages: PyAudio, Whisper, TTS, PyAutoG UI, etc.\n")
    
    import subprocess
    result = subprocess.run(
        [sys.executable, "-m", "pip", "install", "-r", str(requirements_file)],
        capture_output=False
    )
    
    if result.returncode == 0:
        print("\n‚úÖ D√©pendances install√©es")
        return True
    else:
        print("\n‚ùå Erreur lors de l'installation")
        return False


def download_whisper():
    """T√©l√©charge le mod√®le Whisper"""
    print_header("üé§ Configuration de Whisper")
    
    print("Au premier lancement, Whisper t√©l√©chargera automatiquement le mod√®le.")
    print("Mod√®le configur√©: medium (~1.5GB)")
    print("Vous pouvez changer cela dans config.py (WHISPER_MODEL)")
    
    print("\nüí° Test de Whisper...")
    try:
        from faster_whisper import WhisperModel
        print("Chargement du mod√®le (t√©l√©chargement si n√©cessaire)...")
        model = WhisperModel("medium", device="cpu", compute_type="int8")
        print("‚úÖ Whisper pr√™t!")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Whisper sera t√©l√©charg√© au premier lancement: {e}")
        return True


def download_tts():
    """T√©l√©charge le mod√®le TTS"""
    print_header("üîä Configuration de TTS (XTTS v2)")
    
    print("Au premier lancement, TTS t√©l√©chargera automatiquement le mod√®le.")
    print("Mod√®le: XTTS v2 (~2GB)")
    
    print("\nüí° Test de TTS...")
    try:
        from TTS.api import TTS
        print("Chargement du mod√®le (t√©l√©chargement si n√©cessaire)...")
        tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")
        print("‚úÖ TTS pr√™t!")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è TTS sera t√©l√©charg√© au premier lancement: {e}")
        return True


def check_ollama():
    """V√©rifie qu'Ollama est disponible"""
    print_header("üß† V√©rification d'Ollama")
    
    print("V√©rification de la connexion √† Ollama...")
    
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"‚úÖ Ollama connect√© - {len(models)} mod√®les disponibles")
            
            # V√©rifier si qwen2.5 est pr√©sent
            qwen_found = any('qwen2.5' in m.get('name', '').lower() for m in models)
            if qwen_found:
                print("‚úÖ Mod√®le Qwen2.5 trouv√©")
            else:
                print("‚ö†Ô∏è Qwen2.5 non trouv√©")
                print("   Installez-le: ollama pull qwen2.5:7b-instruct-q4_K_M")
            
            # V√©rifier VLM
            vlm_found = any('qwen2-vl' in m.get('name', '').lower() for m in models)
            if vlm_found:
                print("‚úÖ Mod√®le VLM (Qwen2-VL) trouv√©")
            else:
                print("‚ö†Ô∏è VLM non trouv√© (IMPORTANT pour CUA!)")
                print("   Installez-le: ollama pull qwen2-vl:7b")
            
            return True
        else:
            print("‚ùå Ollama non disponible")
            return False
    except Exception as e:
        print(f"‚ùå Erreur connexion Ollama: {e}")
        print("   Assurez-vous qu'Ollama est d√©marr√©")
        print("   T√©l√©chargez: https://ollama.ai")
        return False


def create_directories():
    """Cr√©e les dossiers n√©cessaires"""
    print_header("üìÅ Cr√©ation des dossiers")
    
    base_dir = Path(__file__).parent
    
    directories = [
        base_dir / "data",
        base_dir / "models",
        base_dir / "data" / "screenshots",
    ]
    
    for directory in directories:
        directory.mkdir(parents=True, exist_ok=True)
        print(f"‚úÖ {directory}")
    
    return True


def setup_summary():
    """Affiche un r√©sum√© de la configuration"""
    print_header("üìã R√©sum√© de la Configuration")
    
    print("""
‚úÖ D√©pendances Python install√©es
‚úÖ Whisper (STT) pr√™t
‚úÖ TTS (XTTS v2) pr√™t
‚úÖ Ollama v√©rifi√©
‚úÖ Dossiers cr√©√©s

üéØ Prochaines √©tapes:

1. Assurez-vous qu'Ollama est d√©marr√©:
   - Windows: Ollama doit tourner en arri√®re-plan
   - Mod√®les requis:
     * ollama pull qwen2.5:7b-instruct-q4_K_M
     * ollama pull qwen2-vl:7b  (VLM pour CUA!)

2. Lancez l'agent:
   python main.py

3. Mode texte (sans voix) pour tests:
   python main.py --text

4. Configuration avanc√©e:
   - Modifiez config.py pour personnaliser
   - Calibrez le microphone au premier lancement

üìö Documentation:
   - README.md pour plus d'informations
   - CUA_GUIDE.md pour l'agent autonome
   - INSTALLATION.md pour le guide d√©taill√©
    """)


def main():
    """Script principal de setup"""
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                          ‚ïë
‚ïë         üõ†Ô∏è  MUAG - Setup et Configuration  üõ†Ô∏è            ‚ïë
‚ïë                                                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    # V√©rifications et installations
    steps = [
        ("Version Python", check_python_version),
        ("Dossiers", create_directories),
        ("D√©pendances Python", install_requirements),
        ("Whisper", download_whisper),
        ("TTS", download_tts),
        ("Ollama", check_ollama),
    ]
    
    failed_steps = []
    
    for step_name, step_func in steps:
        try:
            if not step_func():
                failed_steps.append(step_name)
        except Exception as e:
            print(f"\n‚ùå Erreur dans {step_name}: {e}")
            failed_steps.append(step_name)
    
    # R√©sum√©
    if not failed_steps:
        setup_summary()
        return 0
    else:
        print("\n" + "="*60)
        print("‚ö†Ô∏è  Configuration incompl√®te")
        print("="*60)
        print("\n√âtapes √©chou√©es:")
        for step in failed_steps:
            print(f"  - {step}")
        print("\nCorrigez les erreurs et relancez setup_models.py")
        return 1


if __name__ == "__main__":
    sys.exit(main())
