# üöÄ Installation de TARS UI pour l'Agent CUA

## Qu'est-ce que TARS UI?

**TARS UI** (ByteDance) est un mod√®le Vision-Language **sp√©cialis√© pour Computer Use**.  
C'est le c≈ìur de votre agent CUA - il "voit" et "comprend" l'√©cran comme un humain.

## üì• Installation

### Option 1: Via Ollama (Recommand√©)

```bash
# IMPORTANT: TARS UI n'est pas encore dans Ollama officiel
# On utilise donc un VLM alternatif en attendant

# Alternative 1: Qwen2-VL (Excellent pour Computer Use)
ollama pull qwen2-vl:7b

# Alternative 2: LLaVA (Plus l√©ger)
ollama pull llava:7b

# Alternative 3: Qwen2-VL 2B (Si RAM limit√©e)
ollama pull qwen2-vl:2b
```

### Option 2: TARS UI via HuggingFace (Avanc√©)

Si vous voulez le vrai TARS UI:

```bash
# 1. Installer transformers
pip install transformers torch

# 2. Le mod√®le sera t√©l√©charg√© automatiquement
# Chemin HuggingFace: ByteDance/TARS-UI-1.5-7B
```

Puis modifiez `config.py`:
```python
TARS_MODEL_NAME = "ByteDance/TARS-UI-1.5-7B"  # Via HuggingFace
```

## ‚úÖ V√©rification

```bash
# Tester que le VLM fonctionne
ollama run qwen2-vl:7b "D√©cris ce que tu vois"
```

## üéØ Configuration dans config.py

```python
# Mod√®le TARS/VLM √† utiliser
TARS_MODEL_NAME = "qwen2-vl:7b"  # ou "llava:7b"

# Fallback si TARS indisponible
FALLBACK_VLM_MODEL = "qwen2-vl:7b"
```

## üìä Comparaison des Mod√®les

| Mod√®le | Taille | RAM | Pr√©cision | Vitesse |
|--------|--------|-----|-----------|---------|
| **Qwen2-VL 7B** | ~7GB | 12GB+ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **LLaVA 7B** | ~4GB | 8GB+ | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Qwen2-VL 2B** | ~2GB | 6GB+ | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **TARS UI (HF)** | ~15GB | 20GB+ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |

### Recommandation

Pour la plupart des usages: **Qwen2-VL 7B**
- Excellent √©quilibre performance/vitesse
- Sp√©cifiquement entra√Æn√© pour vision de UI
- Supporte bien le fran√ßais

## üß™ Test Rapide

```bash
cd c:\Users\wabad\Downloads\MUAPPG\MUAG
python tests/test_cua.py
```

Choisissez "Test simple" pour v√©rifier que tout fonctionne.

## ‚ö†Ô∏è Probl√®mes Courants

### "Mod√®le non trouv√©"
```bash
# Lister les mod√®les install√©s
ollama list

# Si absent, installer
ollama pull qwen2-vl:7b
```

### "Erreur de m√©moire"
- Utilisez un mod√®le plus l√©ger: `qwen2-vl:2b` ou `llava:7b`
- Fermez les autres applications
- Minimum 8GB RAM recommand√©

### "Vision impr√©cise"
- Utilisez Qwen2-VL 7B ou plus
- Augmentez la r√©solution des screenshots
- Ajoutez plus de contexte dans les prompts

## üéì Utilisation Avanc√©e

### Personnaliser le VLM

Dans `actions/cua_agent.py`:

```python
# Utiliser un mod√®le sp√©cifique
agent = CUAAgent(vlm_model="llava:13b")

# Ou laisser auto-detect
agent = CUAAgent()  # Utilise TARS_MODEL_NAME du config
```

### Optimiser la Vitesse

Dans `config.py`:
```python
# R√©duire la qualit√© pour plus de vitesse
TARS_MODEL_NAME = "qwen2-vl:2b"  # Plus rapide

# Augmenter le d√©lai entre √©tapes
CUA_STEP_DELAY = 2  # Secondes
```

## üìö Resources

- **Qwen2-VL**: https://github.com/QwenLM/Qwen2-VL
- **LLaVA**: https://github.com/haotian-liu/LLaVA
- **TARS UI**: https://huggingface.co/ByteDance/TARS-UI-1.5-7B
- **Ollama**: https://ollama.ai

---

Une fois install√©, votre agent CUA peut accomplir **N'IMPORTE QUELLE T√ÇCHE**! üöÄ
