import json
from datetime import datetime
from .planificateur import Planificateur
from .decomposeur import Decomposeur
from .executeur import Executeur
from .verificateur import Verificateur
from .skill_manager import SkillManager
from .memory_manager import MemoryManager
from .intention_analyzer import IntentionAnalyzer, IntentionType
from utils.interaction_utilisateur import InterfaceUtilisateur
from utils.ollama_client import OllamaClient

class Coordinateur:
    def __init__(self):
        self.planificateur = Planificateur()
        self.decomposeur = Decomposeur()
        self.executeur = Executeur()
        self.verificateur = Verificateur()
        self.skill_manager = SkillManager()
        self.memory = MemoryManager()
        self.interface_utilisateur = InterfaceUtilisateur()
        self.intention_analyzer = IntentionAnalyzer()
        self.ollama_client = OllamaClient()
    
    def traiter_requete(self, requete_utilisateur):
        """
        Point d'entr√©e principal - d√©cide entre r√©pondre et agir
        """
        print(f"\nüîç Analyse de: {requete_utilisateur}")
        
        # Obtenir le contexte
        contexte = self.memory.get_contexte_recent(requete_utilisateur)
        
        # Analyser l'intention
        intention = self.intention_analyzer.analyser(requete_utilisateur, contexte)
        print(f"üí° Intention d√©tect√©e: {intention['type'].value} (confiance: {intention['confiance']:.2f})")
        
        # D√©cision: R√©pondre vs Agir
        if self.intention_analyzer.est_action(intention):
            # MODE ACTION
            return self.traiter_action(requete_utilisateur, intention, contexte)
        else:
            # MODE CONVERSATION
            return self.traiter_conversation(requete_utilisateur, intention, contexte)
    
    def traiter_conversation(self, requete, intention, contexte):
        """Traite une requ√™te conversationnelle"""
        print("üí¨ Mode: CONVERSATION")
        
        # Si c'est une question m√©moire, chercher dans les moments marquants
        if intention['type'] == IntentionType.QUESTION_MEMOIRE:
            moments = self.memory.get_moments_pertinents(requete)
            if moments:
                contexte += "\n\nMoments pertinents:\n"
                for moment in moments[:3]:
                    contexte += f"- {moment['requete']}\n"
        
        # G√©n√©rer une r√©ponse naturelle
        prompt = f"""Tu es un assistant vocal personnel amical et naturel.

Contexte: {contexte}

Utilisateur: "{requete}"

G√©n√®re une r√©ponse naturelle, conversationnelle et personnalis√©e.
Si tu connais les pr√©f√©rences de l'utilisateur, utilise-les.
Sois concis mais chaleureux.
"""
        
        reponse = self.ollama_client.generate(prompt)
        
        # Sauvegarder l'interaction
        self.memory.sauvegarder_interaction(requete, {"type": "conversation", "reponse": reponse})
        
        return reponse
    
    def traiter_action(self, requete, intention, contexte):
        """Traite une requ√™te n√©cessitant des actions"""
        print("üé¨ Mode: ACTION")
        
        # Si ACTION_SIMPLE, ex√©cuter directement sans planification
        if intention['type'] == IntentionType.ACTION_SIMPLE:
            print("‚ö° D√©tection ACTION_SIMPLE ‚Üí Ex√©cution directe")
            return self.traiter_action_simple(requete, intention)

        # Si ACTION_COMPLEXE, router vers CUA
        if intention['type'] == IntentionType.ACTION_COMPLEXE:
            print("ü§ñ D√©tection ACTION_COMPLEXE ‚Üí Routing vers CUA Agent")
            return self.traiter_avec_cua(requete, intention)

        # Sinon, traitement classique avec d√©composition (pour compatibilit√©)
        interactions_similaires = self.memory.get_similar_interactions(requete)
                
        if interactions_similaires:
            print("üìñ Interactions similaires trouv√©es")
        
        plan = self.planificateur.generer_plan(requete, contexte)
        print(f"üìù Plan: {plan}")
        
        graphe_taches = self.decomposeur.analyser_dependances(plan)
        resultats = self.executer_avec_reprise(graphe_taches)
        
        self.apprendre_et_memoriser(graphe_taches, resultats, requete)
        reponse = self.generer_reponse_contextuelle(requete, resultats)
        
        return reponse
    
    def traiter_avec_cua(self, requete, intention):
        """Traite une action complexe directement avec CUA Agent"""
        print(f"üéØ Lancement CUA pour: {requete}")
        
        # Cr√©er une t√¢che unique CUA
        tache_cua = {
            "tache_1": {
                "id": "tache_1",
                "description": requete,
                "type": "cua_complex",
                "dependances": []
            }
        }
        
        graphe = {
            "taches": tache_cua,
            "ordre_execution": ["tache_1"]
        }
        
        # Ex√©cuter avec CUA
        resultats = self.executer_avec_reprise(graphe)
        
        # Sauvegarder sans skills (CUA apprend visuellement)
        self.memory.sauvegarder_interaction(requete, {
            "type": "cua_complex",
            "resultats": resultats,
            "timestamp": datetime.now().isoformat()
        })
        
        # G√©n√©rer r√©ponse
        if resultats.get("tache_1", {}).get("status") == "success":
            return f"T√¢che accomplie avec succ√®s ! {resultats['tache_1'].get('resultat', '')}"
        else:
            return "Je n'ai pas pu accomplir compl√®tement la t√¢che."
    def traiter_action_simple(self, requete, intention):
        """Traite une action simple directement sans planification"""
        print(f"üéØ Ex√©cution action simple: {requete}")
        
        # Cr√©er une t√¢che unique simple
        tache_simple = {
            "tache_1": {
                "id": "tache_1",
                "description": requete,
                "type": "action_simple",
                "dependances": []
            }
        }
        
        graphe = {
            "taches": tache_simple,
            "ordre_execution": ["tache_1"]
        }
        
        # Ex√©cuter directement
        resultats = self.executer_avec_reprise(graphe)
        
        # Sauvegarder (sans cr√©er de skills)
        self.memory.sauvegarder_interaction(requete, {
            "type": "action_simple",
            "resultats": resultats,
            "timestamp": datetime.now().isoformat()
        })
        
        # R√©ponse simple
        if resultats.get("tache_1", {}).get("status") == "success":
            return resultats["tache_1"].get("resultat", "‚úÖ Action ex√©cut√©e")
        else:
            return "‚ùå L'action a √©chou√©"
    
    def executer_avec_reprise(self, graphe_taches):
        resultats = {}
        taches_ignorees = []
        
        for tache_id in graphe_taches["ordre_execution"]:
            tache = graphe_taches["taches"][tache_id]
            
            if self.dependances_satisfaites(tache, resultats):
                execution_result = self.executeur.executer_tache_avec_verification(tache)
                
                # üî• TOUJOURS STOCKER LE DICT COMPLET
                resultats[tache_id] = execution_result
                
                if execution_result["status"] == "success":
                    print(f"‚úÖ {tache['description']} - TERMIN√â")
                elif execution_result["status"] == "user_intervention_failed":
                    print(f"‚è≠Ô∏è {tache['description']} - IGNOR√â")
                    taches_ignorees.append(tache_id)
                elif execution_result["status"] == "failed":
                    print(f"üí• {tache['description']} - √âCHEC")
                    if self.interface_utilisateur.demander_confirmation("Continuer sans cette t√¢che?"):
                        taches_ignorees.append(tache_id)
                    else:
                        break
        
        if taches_ignorees:
            self.verifier_impact_taches_ignorees(taches_ignorees, graphe_taches, resultats)
        
        return resultats
    
    def dependances_satisfaites(self, tache, resultats_existants):
        for dependance in tache.get("dependances", []):
            if dependance not in resultats_existants:
                return False
        return True
    
    def verifier_impact_taches_ignorees(self, taches_ignorees, graphe_taches, resultats):
        for tache_id in graphe_taches["ordre_execution"]:
            if tache_id not in taches_ignorees and tache_id not in resultats:
                tache = graphe_taches["taches"][tache_id]
                for dependance in tache.get("dependances", []):
                    if dependance in taches_ignorees:
                        print(f"‚ö†Ô∏è  '{tache['description']}' d√©pend de '{dependance}' ignor√©e")
    
    def apprendre_et_memoriser(self, graphe_taches, resultats, requete_utilisateur):
        skills_ajoutes = []
        
        for tache_id, execution_data in resultats.items():
            # üî• MAINTENANT execution_data EST TOUJOURS UN DICT
            if execution_data["status"] == "success":
                tache = graphe_taches["taches"][tache_id]
                resultat = execution_data["resultat"]
                commande_utilisee = execution_data["commande_utilisee"]
                
                # Ne pas cr√©er de skills pour les t√¢ches CUA (elles apprennent visuellement)
                if tache.get('type') == 'cua_complex':
                    print("ü§ñ T√¢che CUA - Pas de skill cr√©√© (apprentissage visuel)")
                    continue
                
                if self.verificateur.verifier(tache, resultat):
                    description = tache['description']
                    
                    if commande_utilisee and self.skill_manager.evaluer_reutilisabilite(description, resultat):
                        self.skill_manager.ajouter_skill(description, commande_utilisee)
                        skills_ajoutes.append(description)
                        print(f"üí° Skill cr√©√©: {description}")
        
        # Sauvegarde m√©moire
        self.memory.sauvegarder_interaction(requete_utilisateur, {
            "resultats": {k: v["resultat"] for k, v in resultats.items() if v["status"] == "success"},
            "skills_ajoutes": skills_ajoutes,
            "timestamp": datetime.now().isoformat()
        })
        
        if skills_ajoutes:
            print(f"üéØ Skills ajout√©s: {', '.join(skills_ajoutes)}")
    
    def generer_reponse_contextuelle(self, requete, resultats):
        historique = self.memory.get_contexte_recent(requete)
        
        # Compter les succ√®s
        succes = sum(1 for r in resultats.values() if r["status"] == "success")
        total = len(resultats)
        
        prompt = f"""
        Historique: {historique}
        
        L'utilisateur a demand√©: "{requete}"
        R√©sultat: {succes}/{total} t√¢ches accomplies avec succ√®s.
        
        G√©n√®re une r√©ponse naturelle qui r√©sume ce qui a √©t√© fait.
        Mentionne les nouveaux skills appris si pertinent.
        """
        
        return self.ollama_client.generate(prompt)