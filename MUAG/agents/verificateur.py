from utils.ollama_client import OllamaClient

class Verificateur:
    def __init__(self):
        self.client = OllamaClient()
    
    def verifier(self, tache, resultat):
        # üî• D√âTECTION AUTOMATIQUE DES SUCC√àS
        description = tache['description'].lower()
        resultat_str = str(resultat).lower()
        
        # Si c'est une commande "start" et qu'on a pas d'erreur √©vidente
        if "start" in resultat_str and "erreur" not in resultat_str and "n'est pas reconnu" not in resultat_str:
            print("‚úÖ Succ√®s d√©tect√© automatiquement (commande start)")
            return True
        
        # Si le code retour est 0
        if "code: 0" in resultat_str:
            print("‚úÖ Succ√®s d√©tect√© automatiquement (code 0)")
            return True
        
        # Si la commande a √©t√© lanc√©e en arri√®re-plan
        if "commande lanc√©e" in resultat_str:
            print("‚úÖ Succ√®s d√©tect√© automatiquement (commande lanc√©e)")
            return True
        
        # Fallback: v√©rification par LLM
        prompt = f"""
        T√¢che: {tache['description']}
        R√©sultat: {resultat}
        
        La t√¢che est-elle accomplie avec succ√®s?
        Pour les commandes 'start' qui lancent des applications, consid√®re que c'est r√©ussi si l'application s'ouvre.
        
        R√©ponds uniquement par OUI ou NON.
        """
        reponse = self.client.generate(prompt).strip().upper()
        print(f"üîç V√©rification LLM: {reponse}")
        return reponse == "OUI"